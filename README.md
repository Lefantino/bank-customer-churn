# Построение модели, прогнозирующей отток клиентов банка
Стек: python, pandas, matplotlib, seaborn, numpy, sklearn, imblearn

## Описание целей и задачи проекта
Банк наблюдает отток клиентов, постепенно люди отказываются от их услуг. Ситуация не критическая, но что-то нужно делать.

По поведению клиента необходимо определить, намерен ли он рассторгнуть контракт. Имеется информация о клиентах, их поведении и расторжении договоров. На основе этих данных **нам необходимо построить модель, предсказывающую уход клиента из банка.**

Основная метрика - F1-мера, необходима модель с максимально возможным значением этой метрики. По техническому заданию минимум F1-меры равен 0.59, но мы постораемся сделать модель лучше. Дополнительно будем рассчитывать ROC-AUC, строить ROC-кривые и изучим методы борьбы с дисбалансом.

## План проекта
1. Изучим данные, при наличии проблем с наполнением, исправим их.
2. Проведем исследовательский анализ данных, изучим признаки более подробно, их распределения и зависимости.
3. Подготовим данные к машинному обучению. Закодируем категориальные признаки, отмасштабируем непрерывные.
4. Исследуем проблему несбалансированного распределения целевого признака. Проведем кросс-валидацию четырех моделей:
* Decision Tree
* Random Forest
* LightGBMC
* LogisticRegression 
5. Исследуем способы борьбы с дисбалансом, опробуем 3 способа: downsampling, randomoversampling, SMOTE. Выберем лучший способ.
6. Применяя лучший способ борьбы с дисбалансом, улучшим модели поиском по сетке
7. Протестируем модель.

## Описание данных
Для построения модели прогнозирующий отток клиентов банка нам был предоставлен датасет, содержащий 10000 наблюдений и 14 признаков, описывающий пользователей продукта банка. Признаки датасета описывают клиента с разных сторон, они позволяют нам узнать фамилию клиента, страну проживания, возраст, пол, кредитный рейтинг, баланс на счетах, количество продуктов, которыми пользуется клиент, наличие кредитной карты, активность и даже предполагаемую заработную плату.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## Вывод по проекту
Для построения модели прогнозирующий отток клиентов банка нам был предоставлен датасет, содержащий 10000 наблюдений и 14 признаков, описывающий пользователей продукта банка. Признаки датасета описывают клиента с разных сторон, они позволяют нам узнать фамилию клиента, страну проживания, возраст, пол, кредитный рейтинг, баланс на счетах, количество продуктов, которыми пользуется клиент, наличие кредитной карты, активность и даже предполагаемую заработную плату.

На первом этапе работы мы познакомились с этими признаками, проанализировали их на наличие проблем и выяснили, что в датасете содержится 909 пропусков в столбце **Tenure**, отсутствуют аномальные значения, отсутствуют грубые и неявные дубликаты. Для дальнейшего анализа мы исправили названия признаков, заполнили пропуски в столбце **Tenure**, на основе гипотезы о том, что оригинальное распределение должно быть равномерным, при этом метку 0 получили пользователи ниже медианного возраста, метку 10 - остальные. Так же мы изменили тип данных столбца на более подходящий - int. Для дальнейшего анализа и машинного обучения некоторые признаки были лишними, это идентификатор клиента, фамилия, а так же столбец с индексом. Их мы удалили.

На этапе исследовательского анализа мы выяснили, что:
* Большая часть клиентов, судя по датасету, живет во Франции ~5000 клиентов, а в Германии и Испании примерно поровну, ~2300 клиентов.
* Мужчин среди клиентов банка так же с небольшим перевесом больше. Порядка 55% клиентов - мужчины, остальные клиенты - женщины.  
* Распределение времени, которое клиент пользуется услугами банка практически равномерное (ранее мы дозаполняли пропуски)
* Основная часть клиентов банка пользуется одним продуктом (чуть больше 50%), немного меньше клиентов пользуются двумя продуктами. Очень мало клиентов, пользующихся тремя или четыремя продуктами.  
* Кредитная карта есть не у всех, но у большей части клиентов она есть. 70% клиентов пользуются кредиткой.  
* Примерно 48% клиентов не проявляют активность.
* Возраст клиента: от 18 до 92 лет, основная часть клиентов в возрасте от 30 до 40 лет. Медиана по возрасту - 37 лет.
* Кредитный рейтинг: максимальный 850, минимальный 350, распределение с выраженной отрицательной ассиметрией.
* Баланс: очень много клиентов не имеет денег на счетах. Если отбросить эту категорию, то остальное распределение нормальное.
* Предполагаемая зарплата: распределение близкое к равномерному, минимальная предполагаемая зарплата - 12 евро, маскимальная - 200 тыс. евро. Средняя зарплата - 100 тыс. евро.  

Всего в датасете 3617 клиентов с нулевым балансом, то есть треть клиентов. Довольно большая группа, мы изучили их подробнее и выяснили, что среди этой группы клиентов нет людей из Германии, в основном это Французы. Большая часть таких клиентов пользуется двумя продуктами банка.

Мы построили матрицу корреляции для изучения взаимосвязи между данными и выяснили, что практически все признаке не имеют никакой взаимозависимости. Выделяются только пары: **num_of_products** и **balance**, **age** и **exited**. В первом случае есть слабая отрицательная взаимосвязь. Во втором случае, между **age** и **exited**, слабая положительная связь. Т.к. связь эта слабая, удалять признак Age не будем.

Напоследок мы более подробно изучили целевой признак **exited**, он содержит метки классов 1 и 0, где 1 - означает, что клиент ушел из банка. Распределение классов целевого признака следующее:
* Пользуются услугами банка - 0.7963
* Не пользуются услугами банка - 0.2037


Можно так же выделить, что имеются следующие различия в поведении ушедших и оставшихся клиентов:
* Небольшая разница в признаке пола клиента: уходит больше женщин, чем мужчин
* Остаются в основном пользователи одного-двух продуктов, почти нет тех, кто пользуются 3-4 продуктами, среди ушедших клиентов много пользователей одного продукта, но так же много и тех, кто пользуется 3-4 продуктами банка.
* Средние значение возраста значитетельно выше в группе ушедших клиентов, распределение по возрасту более нормальное, нежели у группы не ушедших клиентов.
* Среди ушедших клиентов наблюдается значительно меньшая доля нулевых балансов, при этом распределения остальных балансов довольно похожи. Как следствие - среднее значение баланса у ушедших клиентов выше. 91 тыс. евро против 72.7 тыс. евро.
* Кредитный рейтинг обоих групп практически не отличается
* Предполагаемая зарплата среди ушедших и не ушедших клиентов так же очень похожа
![image](https://user-images.githubusercontent.com/109238063/200199376-66bc0b53-e877-4ecb-aa98-3fa8c6fdf18b.png)


Для обучения моделей нам необходимо так же подготовить данные особым образом.  
Мы закодировали категориальные признаки методом OHE, а так же разделили данные на обучающую и тестовую выборки в соотношении 3:1, при этом сохранив баланс классов. Кроме того, непрерывные количественные признаки мы привели к единому масштабу с помощную стандартизации.

Начав обучение моделей мы столкнулись с высоким показателем ROC-AUC и низким значением F1-меры. Эта проблема обусловлена сильным дисбалансом классов.
![image](https://user-images.githubusercontent.com/109238063/200199438-251e434f-0f81-47ac-bd69-1bdb054ca888.png)


Для устранения дисбаланса классов мы изучили 3 метода: downsampling, randomoversampling, SMOTE. По результатам кросс-валидации самым эффективным методом оказалось SMOTE - метод, построенный на создании синтетических похожих признаков минорного класса. Далее мы провели тюнинг моделей и в результате модели RandomForest и LightGBMC смогли превысить необходимый порог. Значение F1-мер составляли 0.599 и 0.617 соответственно. Теперь наши модели можно опробовать в тестовой выборке.


Мы протестировали все модели и в результате трем моделям удалось справиться с поставленной задачей и преодолеть порог F-меры, равный 0.59:
* Decision Tree на тестовой выборке получила значение F1-меры, равное 0.591
* Random Forest на тестовой выборке получила значение F1-меры, равное 0.61
* LightGBM на тестовой выборке получила значение F1-меры, равное 0.64

Лучшая модель имеет следующие параметры:
Pipeline(steps=[('sampling', SMOTE(random_state=42)),
                ('clf',
                 LGBMClassifier(class_weight='balanced', max_depth=20,
                                n_estimators=50, random_state=42))])
